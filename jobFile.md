##### 带领团队完成精准派单需求的设计和开发:
* 需求背景:通讯基站经常会因为各种原因产生一些故障.故障发生后,有的会自动恢复,有的则需要人工手动修复.如果属于人工修复的故障,则需通知就近的维修站派维修员实地检修.然而不同的故障在检修时可能需要不同的工具和材料,如果事先不清楚故障的具体信息,则会导致维修员因为维修材料准备不足或工具漏带而多次往返,造成大量的时间和人力浪费,所以在通知维修员前去检修之前要尽可能根据基站发回的运行数据定位出告警的详细信息.精准派单项目便是应这种要求而生,目的是通过分析从基站采集回来的数据,找到告警发生的根本原因,从而准确判断告警类型,做到高效快速地修复故障,节省成本和保持通信畅通.
* 整体流程: 基站工作过程中产生的工作数据和日志会定时上传到中央服务器中,当告警发生后,消息会先反馈到中央控制器.中央控制器控制台收到消息后将任务派发给相关的本地控制器.本地控制器根据alarmId通过ftp将中央服务器上与当前告警相关的配置,硬件监测,话务统计等数据采集到本地,并对原始数据进行初步清洗,处理成合适的结构存入PostgreSQL数据库,入库完成之后启动分析微服务,微服务根据告警信息运行相关诊断算法进行分析,完成后将结果汇总入库并同时推送到中央服务器,中央服务器收到消息后根据处理的结果执行后续的任务派发等工作.整个过程涉及ftpDownlode,dataParse,dataClean,dataImpotr,subjectAnalysis等几个步骤.
* 项目架构: 项目采用微服务架构.Task微服务相当于本地控制器,主管本地任务分发,跟踪和调度.当收到ftp采集完成的消息之后,task通知dataParse微服务将数据解压并归类存放到本地,完成后dataClean微服务进行数据清洗,之后各个dataParse微服务进行数据导入,最后subjectAnalysis微服务根据算法进行数据分析,生成结果并入库,同时向中央控制器推送诊断结论,整个分析过程就此结束. 流程中数据导入的微服务有多个,与原始数据的类型相对应,导入是并行的,每个微服务只管自己需要导入的数据. 不同的微服务通过扫描指定的任务表来完成通信,每个微服务会定时去扫描任务表中有没有自己需要完成的任务,如果有就领取任务,没有则继续扫描.直到领到自己需要做的任务.
* 技术点: 1. 硬件监测,话务统计等数据的格式不统一,有时候可能单条数据也不完整,所以数据清洗是难操作点之一:既要保证清洗流程能尽量统一,又要保证清洗后的格式能够通用,还要判断舍弃无用的废弃数据.最终处理方式是将不同种类的数据根据使用场景分成了四大类,每个类的存储结构有所不同,但是都统一转成json格式入库,使用时也根据对应种类的结构进行解析.  2. 各个微服务之间的调度也是难点之一:考虑到各个微服务之间的通信并不频繁,如果使用消息队列则会增加额外的工作量且难度也会增加很多,而且项目时间和预算也有限,所以最终采取的方案是通过更新和扫描固定的任务表来互通信息.  3. 推送并更新中央数据库的告警信息也是一大难点: 一来是要用到kafuka消息队列,二来是告警恢复时间要考虑的场景多且复杂. 以20分钟一个周期为例,第一个周期发现一个告警,第二个周期这个告警没有再发生,那我就要通过本地数据库中的数据计算出该告警的恢复时间,并将这个时间更新到服务器上,告诉服务器该条告警已经消除了.其中本地数据计算涉及到切库,联查,表数据对比等,且实际中情况并非只隔一个周期那么简单,要精确计算时间很不容易.
* 项目职责: 第二负责人;参与项目整体流程的设计,需求划分,工作量评估,风险评估,人力安排等;参与微服务调度流程逻辑设计;完成数据更新和推送模块核心代码的编写;参与数据清洗模块代码的优化;
##### 带领团队完成lite商用 自动化部署需求的设计和开发
* 需求背景: lite的需求涉及到环境的部署,以往在新环境上部署都是人力手动去拷贝相应的自动化包和需要的各种文件,拷贝完成之后再手动执行相应的脚本文件,以对整个环境全新安装或者升级部署.但是人工操作容易出错,且在需要部署集群环境时会耗费大量的时间和精力,远不能满足高效快速的开发要求.基于这种考虑,该需求便应运而生.以期能够通过简单的页面点击,实现跨虚拟机单机器或者集群机器的快速部署.
* 整体流程: 首先在目标环境上拷贝一份自动化部署的微服务并启动,这个微服务就是控制所有环境部署的控制中心.通过浏览器输入部署地址进入到部署页面,根据页面提示填写待部署的环境信息,然后启动部署,微服务便会自动去完成拷贝和启动各种脚本文件的操作.启动后会跳转日志页面,可以根据需求选择展示对应环境的部署日志信息.等到所有环境都部署完成之后,会有验证环境基本功能是否正常的环节,通常包括kafka,ftp,hbase等功能的验证.如果验证都没有问题,则说明当前环境已经部署完成.
* 项目架构 : 该项目是一个典型的javaWeb项目,使用tomcat部署一个后台服务,并配套相应的web页面,与部署有关的控制流程以及部署完成之后的验证等流程都是在页面上完成,包括机器验证,功能case选择,附加项选择,日志展示,基础功能调测等页面.按照页面提示即可完成操作.
* 技术点 : 1.生产环境上部署的微服务往往不止一个,如果有很多微服务同时启动但是却不在工作中肯定会导致环境卡顿资源浪费,所以环境都有弹性伸缩机制,那些暂时用户不到的微服务会被自动终止.由于在环境部署时需要跨虚拟机拷贝大量文件,耗时很长,且启动脚本也需要大量时间来执行,有时候微服务会有被误杀的风险,所以这个自动化微服务不能使用生产环境原有的java环境,需要自带jre以避免自身的进程被环境误杀. 2.集群的部署涉及到大量跨虚拟机的数据拷贝和脚本调用,对相关doc命令的熟悉程度,以及java侧对各种命令的调用方式和写法需要多留心. 
* 职责: 项目第一负责人;负责设计项目的整体流程,需求划分,工作安排,进度把控等;配置tomcat单独的jre环境;完成doc命令以及调用doc命令java代码的编写.

##### 安徽爱普科技
* 一个大型javaWeb项目.是安徽六安那边各县区民政数据的展示平台,展示各个县区的医疗,卫生,教育,交通,补助等各种数据,并提供数据查询功能.主要负责数据的处理.
大多是xml,csv,json等格式的数据解析和入库,调用接口绘制各种图表,编写分页查询接口等.

##### python爬虫
* 能编写一些常用的python爬虫.算不上多厉害,大多都是出于兴趣写的一些小爬虫,抓取些感兴趣的东西.



##### 技能:
* 熟练使用java,python编程语言.
* 熟练使用sql,postgreSQL数据库. 
* 熟练使用 git,svn,maven,ant等版本和项目管理工具. 
* 熟悉spring ,mybatis框架.
* 熟练使用eclipse,pycharm集成开发环境.
* 熟练使用linux操作系统

* 熟悉nosql;会用hbase数据库,了解其原理.
* 会用kafka消息队列,能够用java线程实现简单消息队列.
* 熟悉VMware虚拟机,能够搭建虚拟环境
* 了解http,tcp等常见网络协议.
* 能看懂JavaScript,html,css代码. 
