#### 编码和解码的本质
1. 计算机中所有的东西都是用0和1来表示. 而这么多0和1对应的就是硬件中的晶体管开关. 别小看计算机中那点电路板,就那点电路板中可焊着成百上千亿的晶体管,
计算机就是用那么多晶体管的通电和不通电(也就是打开和关闭)来表示0和1的.
2. 计算机能处理那么多0和1,但是人不行,10001110101010001101110100011010.给你这一串0和1你能记住吗?所以有了编码和字符集的概念.计算机是人家美国佬发明的,
所以最开始出现的字符集就是ASCII字符集,这个字符集给所有的英文字母和数字还有各种标点符号编了个码.那时候一块电路板上并排最多只能焊接8个晶体管,所以也就会
有8根线,所以一次性传递的电流信号也就有8个,就是后来我们所谓的8个二进制位,也就是8比特,8bit.但是一个比特一个比特的数很麻烦,所以后来就规定,8个比特等于一个
byte,也就是一个字节,别把bit和byte搞混了,bit读作比特,而byte读作败特,一个byte=8个bit. 假如我用晶体管1开,2开,3关,4开,5关,6关,7关,8开来表示一个字母'A',
那么继续这样组合,就可以组合出256种情况(2的8次方),而所有的英文字母和数字还有各种标点符号加起来也就128个,所以ASSCII码就是用一个字节(8个比特),来表示一个
字符(因为够用了).假如你的电路板上面焊了1万个晶体管,现在你想把'I LOVE YOU'这句话存到计算机里,那么计算机就会拿出64个晶体管来存这8个字符,不管是横着存还是
竖着存,总之每8个晶体管存一个字母.这就是存储的基本原理.
3. 后来随着计算机的普及,各个国家的字母和符号也不断增加,显然一个字节(可以表示256中情况)已经无法满足存储要求,汉子就有几千多个呢.所以后来出现了Unicode.
所谓的Unicode其实是一种字符集,你不是一个字节不够用吗,那好我现在用两个甚至三个字节,最多四个字节来表示一个字符,四个字节能表示(2的32次方)65536中情况,
这样全世界所有的字符都可表示了. Unicode给世界上每一个字符都分配了一个编码,每个编码都是四个字节,比如我用 00001111 01010011 00111111 11101010这四个
字节来表示'中'(举例用的,实际上中不是这个表示),反正是世界上所有的字符都分配了一个唯一的码.这样的话至少是全世界的字符都能表示了.这时候问题出现了,Unicode
虽然给每个字符分配了码,但是并没有规定怎么往计算机了存这些码. 比如'A'这个字母, 原本我只要00110101这一个byte就可以表示,但你现在多给了我三个字节,这三个
肯定就浪费了,没存东西,utf-8就是这种情况下出现的, utf8并不是一种编码规则,只是在往计算机中存这些码的时候定义的一种存储规则,你不是多了三个字节吗,那好我
存的时候用到的我就存,多余的我就给别的字符用,避免浪费. 比如刚我用 00001111 01010011 00111111 11101010来表示'中',通过utf8这一加工之后,我只需要用
11100011 10110011 10111100这三个字节就可在内存里表示了,那不就节省了一个字节的位置吗.所以utf8只是对Unicode码做了一次变通,最终存到计算机里的就是变通
过之后的这个字节序列,而不是真正的Unicode字节序列.
4. 举个python代码中编码和解码的例子:
'''
a = '中国'             #在python中定义一个字符串默认是用Unicode编码的,
                       # 假设码是 00110011 10101010 01010101 11110011 11110000 00101010 11101010 00001100
b = a.encode('utf-8')  # 这里的encode并不是再一次编码,而是说用utf8的方式来处理这个原始字节串.相当于是把一种语言翻译成另外一种语言
                       # 假设处理过之后b的码就成了 10101100 11110101 00101100 10101101 00110100 
c = b.decode('utf-8')  # 这里是又把用utf8表示的字节串又给翻译成原来的码了,也就是又翻译成Unicode了.代码中的大多问题往往都是出在这里,
                       # 你用啥编,你就用啥解;没编过就不要解;编一次就解一次,别多编也别多解. 
'''
5. 假如你写了一个用bgk编码的文档,当你在java的环境中读取这个文档的时候就有可能出现乱码,因为java的环境默认的编码是跟程序编码走的,一般代码工具比如eclipse都是默认utf8的编码,所以在内存中读的时候java就是按照默认的utf8去解析和读的,自然就会出现乱码. 写也是同一个道理,在代码中创建的字符串是utf8,那么但是你的系统是gbk,那么写到文档里的东西肯定就乱码了. 解决这种问题的办法有,要么你读的时候就用gbk去读,创建字符串的时候也用gbk去创建,写入也用gbk去写,要么就是把文档的存储方式也就是系统的编码改成和工具一样的.只能这样,别的好像没啥好办法.有的人可能会说,不能把gbk直接转换成utf8吗,可以是可以,但是这种就复杂了,gbk和utf8是两种完全没关系的编码体系,它们之间根本没有对应关系.即便你有人说你可以先把gbk转成Unicode然后再.......但实际上计算机根本不知道两种编码的字节串对应的是不是同一个字符,比如'中'在gbk的码是123,在Unicode的码是456,人确是认得这个字是'中',但计算机不知道,内存中的gbk的123咋知道自己要和Unicode的456去对应呢?根本不知道. 所以,如果你的文件只是你自己用,你用啥编码都没问题,你自己知道就行,但是假如你的文档是要广泛传播的,那么原始的编码选择就显得很重要了,因为别人不知道你原始的码,自然解起来就相当费事. 最好是都指定utf8作为默认的编码.
6. 如果照这种理解的话,好像utf8也可以直接理解成一种编码方式,不用再把它理解成Unicode的实现,而直接理解成一种新的编码方式.恩,不错,没毛病!!!
